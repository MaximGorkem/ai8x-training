{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MOFA: Maxim's Once For All ###\n",
    "### This version is using the Kernel Transition Matrix by default. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.cifar100 import cifar100_get_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Classes</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clamp(nn.Module):\n",
    "    \"\"\"\n",
    "    Post-Activation Clamping Module\n",
    "    Clamp the output to the given range (typically, [-128, +127])\n",
    "    \"\"\"\n",
    "    def __init__(self, min_val=None, max_val=None):\n",
    "        super().__init__()\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def forward(self, x):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Forward prop\"\"\"\n",
    "        return x.clamp(min=self.min_val, max=self.max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOFAnet(nn.Module):\n",
    "    # Maxim OFA Net\n",
    "    def __init__(self, param_dict):\n",
    "        super(MOFAnet, self).__init__()\n",
    "        self.param_dict = param_dict\n",
    "        self.in_ch = param_dict['in_ch']\n",
    "        self.out_class = param_dict['out_class']\n",
    "        self.n_units = param_dict['n_units']\n",
    "        self.width_list = param_dict['width_list']\n",
    "        self.kernel_list = param_dict['kernel_list']\n",
    "        self.bias_list = param_dict['bias_list']\n",
    "        self.bn = param_dict['bn']\n",
    "        self.last_width = self.in_ch\n",
    "        self.units = nn.ModuleList([])\n",
    "        for i in range(n_units):\n",
    "            self.units.append(Unit(len(self.kernel_list[i]), \n",
    "                                   self.kernel_list[i],\n",
    "                                   self.width_list[i], \n",
    "                                   self.last_width, \n",
    "                                   self.bias_list[i],\n",
    "                                   self.bn))\n",
    "            self.last_width = self.width_list[i][-1]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.classifier = nn.Linear(1024, self.out_class) \n",
    "    def forward(self, x):\n",
    "        for i, unit in enumerate(self.units[:-1]):\n",
    "            x = unit(x)\n",
    "            x = self.max_pool(x)\n",
    "        x = self.units[-1](x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit(nn.Module):\n",
    "    def __init__(self, depth, kernel_list, \n",
    "                 width_list, init_width, bias_list, bn=True):\n",
    "        super(Unit, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.kernel_list = kernel_list\n",
    "        self.width_list = width_list\n",
    "        self.bias_list = bias_list\n",
    "        self.bn = bn\n",
    "        self._width_list = [init_width] + width_list\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(depth):\n",
    "            self.layers.append(\n",
    "                FusedConv2dReLU(self._width_list[i],\n",
    "                                self._width_list[i+1],\n",
    "                                self.kernel_list[i],\n",
    "                                self.bias_list[i],\n",
    "                                self.bn))\n",
    "    def forward(self, x):\n",
    "        for i in range(self.depth):\n",
    "            x = self.layers[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedConv2dReLU(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            bias=True,\n",
    "            bn=True):\n",
    "        super(FusedConv2dReLU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "            \n",
    "        ktm_core = torch.zeros((9, 1))\n",
    "        ktm_core[4] = 1\n",
    "        self.ktm = nn.Parameter(data=ktm_core, requires_grad=True)\n",
    "        \n",
    "        if kernel_size == 1:\n",
    "            self.pad = 0\n",
    "        elif kernel_size == 3:\n",
    "            self.pad = 1\n",
    "        else:\n",
    "            raise ValueError\n",
    "        self.func = F.conv2d\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels,\n",
    "                                kernel_size=3, stride=1,\n",
    "                                padding=1, bias=bias)\n",
    "        self.bn = bn\n",
    "        if self.bn:\n",
    "            self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.clamp = Clamp(min_val=-1, max_val=1)\n",
    "    def forward(self, x):        \n",
    "        weight = self.conv2d.weight\n",
    "        bias = self.conv2d.bias\n",
    "        if self.kernel_size == 1:\n",
    "            flattened_weight = weight.view(weight.size(0), weight.size(1), -1, 9)\n",
    "            weight = flattened_weight.to(device) @ self.ktm.to(device)\n",
    "                    \n",
    "        x = self.func(x, weight, bias, self.conv2d.stride, self.pad)\n",
    "        if self.bn:\n",
    "            x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "#         x = self.clamp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Functions</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm Related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bn_stats_false(model):\n",
    "    for u_ind, unit in enumerate(model.units):\n",
    "        for l_ind, layer in enumerate(unit.layers):\n",
    "            model.units[u_ind].layers[l_ind].batchnorm.track_running_stats = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_bn_stats_true(model):\n",
    "    for u_ind, unit in enumerate(model.units):\n",
    "        for l_ind, layer in enumerate(unit.layers):\n",
    "            model.units[u_ind].layers[l_ind].batchnorm.track_running_stats = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def fuse_bn(conv, bn):\n",
    "    w = conv.weight\n",
    "    mean = bn.running_mean\n",
    "    var_sqrt = torch.sqrt(bn.running_var + bn.eps)\n",
    "    beta = bn.weight\n",
    "    gamma = bn.bias\n",
    "    if conv.bias is not None:\n",
    "        b = conv.bias\n",
    "    else:\n",
    "        b = mean.new_zeros(mean.shape)\n",
    "    w = w * (beta / var_sqrt).reshape([conv.out_channels, 1, 1, 1])\n",
    "    b = (b - mean) / var_sqrt * beta + gamma\n",
    "    fused_conv = nn.Conv2d(conv.in_channels,\n",
    "                         conv.out_channels,\n",
    "                         conv.kernel_size,\n",
    "                         conv.stride,\n",
    "                         conv.padding,\n",
    "                         bias=True)\n",
    "    fused_conv.weight = nn.Parameter(w)\n",
    "    fused_conv.bias = nn.Parameter(b)\n",
    "    return fused_conv\n",
    "\n",
    "\n",
    "def fuse_bn_mofa(mofa_net):\n",
    "    param_dict = copy.deepcopy(mofa_net.param_dict)\n",
    "    param_dict['bn'] = False\n",
    "    fused_model = MOFAnet(param_dict)\n",
    "    with torch.no_grad():\n",
    "        fused_model.classifier.weight.copy_(mofa_net.classifier.weight)\n",
    "        fused_model.classifier.bias.copy_(mofa_net.classifier.bias)\n",
    "    for u_ind, unit in enumerate(mofa_net.units):\n",
    "        for l_ind, layer in enumerate(unit.layers):\n",
    "            fused_conv = fuse_bn(layer.conv2d, layer.batchnorm)\n",
    "            fused_conv = fused_conv.to(device)\n",
    "            with torch.no_grad():\n",
    "                fused_model.units[u_ind].layers[l_ind].conv2d.weight.copy_(fused_conv.weight)\n",
    "                fused_model.units[u_ind].layers[l_ind].conv2d.bias.copy_(fused_conv.bias)\n",
    "    return fused_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Kernel - Depth -Width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_subnet_kernel(mofa):\n",
    "    param_dict = copy.deepcopy(mofa.param_dict)\n",
    "    for u_ind, unit in enumerate(mofa.units):\n",
    "        for l_ind, layer in enumerate(unit.layers):\n",
    "            param_dict['kernel_list'][u_ind][l_ind] = random.choice([1, 3])\n",
    "#     param_dict['kernel_list'][0][0] = random.choice([1, 3])\n",
    "#     param_dict['kernel_list'][0][1] = random.choice([1, 3])\n",
    "#     param_dict['kernel_list'][0][2] = random.choice([1, 3])\n",
    "    param_dict['bn'] = False\n",
    "    subnet = MOFAnet(param_dict)\n",
    "    with torch.no_grad():\n",
    "        subnet.classifier.weight.copy_(mofa.classifier.weight)\n",
    "        subnet.classifier.bias.copy_(mofa.classifier.bias)\n",
    "        for u_ind, unit in enumerate(mofa.units):\n",
    "            for l_ind, layer in enumerate(unit.layers):\n",
    "                subnet.units[u_ind].layers[l_ind].conv2d.weight.copy_(mofa.units[u_ind].layers[l_ind].conv2d.weight)\n",
    "                subnet.units[u_ind].layers[l_ind].ktm.copy_(mofa.units[u_ind].layers[l_ind].ktm)\n",
    "                if mofa.bias_list[u_ind][l_ind] is True:\n",
    "                    subnet.units[u_ind].layers[l_ind].conv2d.bias.copy_(mofa.units[u_ind].layers[l_ind].conv2d.bias)\n",
    "    return subnet\n",
    "\n",
    "def update_mofa_from_subnet_kernel(mofa, subnet):\n",
    "    with torch.no_grad():\n",
    "        mofa.classifier.weight.copy_(subnet.classifier.weight)\n",
    "        mofa.classifier.bias.copy_(subnet.classifier.bias)\n",
    "        for u_ind, unit in enumerate(mofa.units):\n",
    "            for l_ind, layer in enumerate(unit.layers):\n",
    "                mofa.units[u_ind].layers[l_ind].conv2d.weight.copy_(subnet.units[u_ind].layers[l_ind].conv2d.weight)\n",
    "                mofa.units[u_ind].layers[l_ind].ktm.copy_(subnet.units[u_ind].layers[l_ind].ktm)\n",
    "                if mofa.bias_list[u_ind][l_ind] is True:\n",
    "                    mofa.units[u_ind].layers[l_ind].conv2d.bias.copy_(subnet.units[u_ind].layers[l_ind].conv2d.bias)\n",
    "    return mofa\n",
    "\n",
    "\n",
    "def sample_subnet_depth(mofa, sample_kernel=True):\n",
    "    param_dict = copy.deepcopy(mofa.param_dict)\n",
    "    depth_list = []\n",
    "    for u_ind in range(len(param_dict['width_list'])):\n",
    "        max_depth = len(param_dict['width_list'][u_ind])\n",
    "        min_depth = 1\n",
    "        depth_list.append(random.randint(min_depth, max_depth))\n",
    "    \n",
    "    if sample_kernel:\n",
    "        subnet = sample_subnet_kernel(mofa) # This is confirmed by Ji\n",
    "    else:\n",
    "        subnet = copy.deepcopy(mofa)\n",
    "    \n",
    "    param_dict = copy.deepcopy(subnet.param_dict)\n",
    "    param_dict['bn'] = False\n",
    "    param_dict['width_list'] = [lst[:depth_list[ind]] for ind, lst in enumerate(subnet.param_dict['width_list'])]\n",
    "    param_dict['kernel_list'] = [lst[:depth_list[ind]] for ind, lst in enumerate(subnet.param_dict['kernel_list'])]\n",
    "    param_dict['bias_list'] = [lst[:depth_list[ind]] for ind, lst in enumerate(subnet.param_dict['bias_list'])]\n",
    "    \n",
    "    subnet2 = MOFAnet(param_dict)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        subnet2.classifier.weight.copy_(subnet.classifier.weight)\n",
    "        subnet2.classifier.bias.copy_(subnet.classifier.bias)\n",
    "        for u_ind, unit in enumerate(subnet2.units):\n",
    "            for l_ind, layer in enumerate(unit.layers):\n",
    "                subnet2.units[u_ind].layers[l_ind].conv2d.weight.copy_(subnet.units[u_ind].layers[l_ind].conv2d.weight)\n",
    "                subnet2.units[u_ind].layers[l_ind].conv2d.bias.copy_(subnet.units[u_ind].layers[l_ind].conv2d.bias)\n",
    "        \n",
    "    return subnet2, param_dict, depth_list\n",
    "\n",
    "def update_mofa_from_subnet_depth(mofa, subnet):\n",
    "    subnet_params = subnet.param_dict\n",
    "    mofa_params = mofa.param_dict\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mofa.classifier.weight.copy_(subnet.classifier.weight)\n",
    "        mofa.classifier.bias.copy_(subnet.classifier.bias)\n",
    "        for u_ind, unit in enumerate(subnet.units):\n",
    "                for l_ind, layer in enumerate(unit.layers):\n",
    "                    mofa.units[u_ind].layers[l_ind].conv2d.weight.copy_(subnet.units[u_ind].layers[l_ind].conv2d.weight)\n",
    "                    mofa.units[u_ind].layers[l_ind].ktm.copy_(subnet.units[u_ind].layers[l_ind].ktm)\n",
    "                    if mofa.bias_list[u_ind][l_ind] is True:\n",
    "                        mofa.units[u_ind].layers[l_ind].conv2d.bias.copy_(subnet.units[u_ind].layers[l_ind].conv2d.bias)\n",
    "    return mofa\n",
    "                \n",
    "def order_channels(mofa):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "def sample_subnet_width(mofa):\n",
    "    mofa = order_channels(mofa)\n",
    "    return mofa\n",
    "\n",
    "    \n",
    "# def update_mofa_from_subnet_width(mofa, subnet):\n",
    " #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_with_soft_target(pred, soft_target):\n",
    "    logsoftmax = nn.LogSoftmax()\n",
    "    return torch.mean(torch.sum(- soft_target * logsoftmax(pred), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> MOFA Training </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 5\n",
    "n_layers = 3\n",
    "\n",
    "param_dict = {}\n",
    "param_dict['n_units']     = n_units\n",
    "param_dict['in_ch']       = 3\n",
    "param_dict['out_class']   = 100\n",
    "param_dict['width_list']  = [[256]*n_layers for _ in range(n_units)]\n",
    "param_dict['kernel_list'] = [[3]*n_layers for _ in range(n_units)]\n",
    "param_dict['bias_list']   = [[True]*n_layers for _ in range(n_units)]\n",
    "param_dict['bn']          = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# class Args():\n",
    "#     def __init__(self):\n",
    "#         super(Args, self).__init__()\n",
    "#         self.truncate_testset = False\n",
    "#         self.act_mode_8bit = False\n",
    "        \n",
    "# args = Args()\n",
    "# train_dataset, test_dataset = cifar100_get_datasets(('data', args))\n",
    "\n",
    "# trainset = DataLoader(dataset=train_dataset,\n",
    "#                       batch_size=100,\n",
    "#                       shuffle=True,\n",
    "#                       num_workers=0)\n",
    "\n",
    "# valset = DataLoader(dataset=test_dataset,\n",
    "#                       batch_size=1000,\n",
    "#                       shuffle=False,\n",
    "#                       num_workers=0)\n",
    "\n",
    "# mofa = MOFAnet(param_dict)\n",
    "# mofa = mofa.to(device)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(mofa.parameters(), lr=1e-4)\n",
    "# scheduler = StepLR(optimizer, step_size=35, gamma=0.4)\n",
    "\n",
    "# best_val_accuracy = 0\n",
    "# max_epochs = 150\n",
    "# for epoch in range(max_epochs):\n",
    "#     t0 = time.time()\n",
    "#     mofa.train()\n",
    "#     for batch, labels in trainset:\n",
    "#         batch, labels = batch.to(device), labels.to(device)\n",
    "        \n",
    "#         y_pred = mofa(batch)\n",
    "#         loss = criterion(y_pred, labels)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     scheduler.step()\n",
    "    \n",
    "#     print(f'Epoch {epoch+1}')\n",
    "#     print(f'\\tTraining loss:{loss.item()}')\n",
    "#     t1 = time.time()\n",
    "#     print(f'\\tTraining time:{t1-t0:.2f} s - {(t1-t0)/60:.2f} mins ')\n",
    "#     # Validation\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     mofa.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for data in valset:\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = mofa(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     val_accuracy = correct / total\n",
    "#     if val_accuracy > best_val_accuracy:\n",
    "#         if epoch != 0:\n",
    "#             os.remove(f'mofa_models/noclamp_mofa_acc{100*best_val_accuracy:.0f}%.pth.tar')\n",
    "#         torch.save(mofa, f'mofa_models/noclamp_mofa_acc{100*val_accuracy:.0f}%.pth.tar')\n",
    "#         best_val_accuracy = val_accuracy\n",
    "#     print('\\tAccuracy of the mofa on the test images: %d %%' % (\n",
    "#         100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Elastic Kernel Training </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('mofa_models/noclamp_mofa_acc71%.pth.tar')\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model = fuse_bn_mofa(model)\n",
    "mofa = copy.deepcopy(fused_model)\n",
    "fused_model = fused_model.to(device)\n",
    "mofa = mofa.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 961.57 MiB already allocated; 11.44 MiB free; 986.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5755eefa280c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkd_ratio\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-60fe393201a6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                             self.return_indices)\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     return torch.max_pool2d(\n\u001b[0m\u001b[1;32m    586\u001b[0m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 961.57 MiB already allocated; 11.44 MiB free; 986.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "kd_ratio = 0.5\n",
    "\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        super(Args, self).__init__()\n",
    "        self.truncate_testset = False\n",
    "        self.act_mode_8bit = False\n",
    "        \n",
    "args = Args()\n",
    "train_dataset, test_dataset = cifar100_get_datasets(('data', args))\n",
    "\n",
    "trainset = DataLoader(dataset=train_dataset,\n",
    "                      batch_size=100,\n",
    "                      shuffle=True,\n",
    "                      num_workers=0)\n",
    "\n",
    "valset = DataLoader(dataset=test_dataset,\n",
    "                      batch_size=1000,\n",
    "                      shuffle=False,\n",
    "                      num_workers=0)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_accuracy = 0\n",
    "max_epochs = 250\n",
    "for epoch in range(max_epochs):\n",
    "    t0 = time.time()\n",
    "    mofa.train()\n",
    "    for batch, labels in trainset:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        \n",
    "#         mofa = make_bn_stats_false(mofa)\n",
    "        subnet = sample_subnet_kernel(mofa)\n",
    "        subnet = subnet.to(device)\n",
    "        optimizer = torch.optim.SGD(subnet.parameters(), lr=1e-3)\n",
    "      \n",
    "        y_pred = subnet(batch)\n",
    "        \n",
    "        if kd_ratio > 0:\n",
    "            fused_model.train()\n",
    "            with torch.no_grad():\n",
    "                soft_logits = fused_model(batch).detach()\n",
    "                soft_label = F.softmax(soft_logits, dim=1)\n",
    "            kd_loss = cross_entropy_loss_with_soft_target(y_pred, soft_label)\n",
    "            loss = kd_ratio * kd_loss + criterion(y_pred, labels)\n",
    "        else:\n",
    "            loss = criterion(y_pred, labels)     \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        mofa = update_mofa_from_subnet_kernel(mofa, subnet)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'\\tTraining loss:{loss.item()}')\n",
    "    t1 = time.time()\n",
    "    print(f'\\tTraining time:{t1-t0:.2f} s - {(t1-t0)/60:.2f} mins ')\n",
    "    \n",
    "    # Validation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    mofa.eval()\n",
    "    with torch.no_grad():\n",
    "#         mofa = make_bn_stats_true(mofa)\n",
    "#         mofa.train()\n",
    "#         for data in valset:\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = mofa(images)\n",
    "#         mofa.eval()\n",
    "        for data in valset:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = mofa(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "#     if val_accuracy > best_val_accuracy:\n",
    "#         if epoch is not 0:\n",
    "#             os.remove(f'mofa_models/ofa_acc{100*best_val_accuracy:.0f}%.pth.tar')\n",
    "#         torch.save(mofa, f'mofa_models/ofa_acc{100*val_accuracy:.0f}%.pth.tar')\n",
    "#         best_val_accuracy = val_accuracy\n",
    "    print('\\tAccuracy of the mofa on the test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    print(f'\\tFirst ktm: {mofa.units[0].layers[0].ktm[4].item()}')\n",
    "    print(f'\\tLast ktm: {mofa.units[4].layers[2].ktm[4].item()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Testing <ins/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOFA Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        super(Args, self).__init__()\n",
    "        self.truncate_testset = False\n",
    "        self.act_mode_8bit = False\n",
    "        \n",
    "args = Args()\n",
    "train_dataset, test_dataset = cifar100_get_datasets(('data', args))\n",
    "\n",
    "trainset = DataLoader(dataset=train_dataset,\n",
    "                      batch_size=100,\n",
    "                      shuffle=True,\n",
    "                      num_workers=0)\n",
    "\n",
    "valset = DataLoader(dataset=test_dataset,\n",
    "                      batch_size=100,\n",
    "                      shuffle=False,\n",
    "                      num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7051\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "mofa.eval()\n",
    "with torch.no_grad():\n",
    "    for data in valset:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = mofa(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_channels(mofa):\n",
    "    for ind in range((n_units*n_layers)-1):\n",
    "        u_ind = ind // n_layers\n",
    "        l_ind = ind % n_layers\n",
    "        layer = mofa.units[u_ind].layers[l_ind]\n",
    "        \n",
    "        importance = torch.sum(torch.abs(layer.conv2d.weight.data), dim=(1, 2, 3))\n",
    "        _, inds = torch.sort(importance, descending=True)\n",
    "        layer.conv2d.weight.data = layer.conv2d.weight.data[inds, :, :, :]\n",
    "        layer.conv2d.bias.data = layer.conv2d.bias.data[inds]\n",
    "        \n",
    "        ind_new = ind + 1\n",
    "        u_ind = ind_new // n_layers\n",
    "        l_ind = ind_new % n_layers\n",
    "        mofa.units[u_ind].layers[l_ind].conv2d.weight.data = mofa.units[u_ind].layers[l_ind].conv2d.weight.data[:, inds, :, :]\n",
    "        \n",
    "    return mofa\n",
    "\n",
    "    \n",
    "def see_channel_importances(mofa):\n",
    "    for u_ind, unit in enumerate(mofa.units):\n",
    "                for l_ind, layer in enumerate(unit.layers):\n",
    "                    importance = torch.sum(torch.abs(layer.conv2d.weight.data), dim=(1, 2, 3))\n",
    "                    print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mofa = sort_channels(mofa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([52.2155, 49.9688, 48.7137, 47.7936, 43.0445, 41.2706, 41.1886, 39.0327,\n",
      "        37.9445, 37.4216, 36.3574, 34.3126, 32.8328, 32.7713, 31.9814, 31.5286,\n",
      "        30.7265, 29.8918, 29.8626, 29.7444, 29.4663, 29.3193, 29.0832, 28.8199,\n",
      "        28.7962, 28.4378, 27.9413, 27.8418, 27.0945, 27.0935, 26.6975, 26.3430,\n",
      "        26.1570, 26.1327, 26.1167, 26.0389, 25.8284, 25.3495, 25.2784, 25.2092,\n",
      "        25.1281, 24.8885, 24.6520, 24.3132, 24.0459, 23.9084, 23.4436, 23.2229,\n",
      "        23.1052, 22.8207, 22.7445, 22.6872, 22.5672, 22.5346, 22.3246, 22.2832,\n",
      "        22.2546, 22.1327, 22.0078, 21.8441, 21.8223, 21.8218, 21.4960, 21.4390,\n",
      "        21.3385, 20.9553, 20.9107, 20.8229, 20.7871, 20.6867, 20.5277, 20.5038,\n",
      "        20.2273, 20.0780, 20.0688, 19.8455, 19.6425, 19.6403, 19.6170, 19.5640,\n",
      "        19.4884, 19.4858, 19.4147, 19.2329, 19.1154, 19.1020, 18.8236, 18.6821,\n",
      "        18.6073, 18.5862, 18.5680, 18.1918, 18.1833, 18.1732, 17.9338, 17.9270,\n",
      "        17.8077, 17.6107, 17.5430, 17.4048, 17.0342, 16.9677, 16.9148, 16.9124,\n",
      "        16.8566, 16.7474, 16.7136, 16.5503, 16.5222, 16.2844, 16.2567, 16.2374,\n",
      "        16.1555, 16.0451, 15.9623, 15.7076, 15.6620, 15.5435, 15.5113, 15.4612,\n",
      "        15.4328, 15.2942, 15.2893, 15.1941, 15.1655, 15.1586, 15.0801, 14.9253,\n",
      "        14.8787, 14.8748, 14.8208, 14.8123, 14.8087, 14.7665, 14.4360, 14.3911,\n",
      "        14.3365, 14.3341, 14.1663, 14.1215, 14.0112, 13.8551, 13.7912, 13.7119,\n",
      "        13.6750, 13.5409, 13.3824, 13.2995, 13.2674, 13.2556, 13.2192, 13.1001,\n",
      "        13.0335, 12.9275, 12.8741, 12.8012, 12.7330, 12.7001, 12.5485, 12.4954,\n",
      "        12.4438, 12.4185, 12.4180, 12.3213, 12.2742, 12.2328, 12.1130, 12.0752,\n",
      "        12.0567, 11.9820, 11.9626, 11.9590, 11.9485, 11.8449, 11.8384, 11.8368,\n",
      "        11.5751, 11.5375, 11.4896, 11.4650, 11.4587, 11.4146, 11.3958, 11.3697,\n",
      "        11.3421, 11.2156, 11.1848, 11.1778, 11.1734, 11.1364, 11.0890, 11.0570,\n",
      "        11.0192, 10.9653, 10.9468, 10.8731, 10.8299, 10.8022, 10.7405, 10.7253,\n",
      "        10.6603, 10.6505, 10.5091, 10.4996, 10.4822, 10.4638, 10.3478, 10.3259,\n",
      "        10.2490, 10.0946, 10.0721,  9.9785,  9.9516,  9.8430,  9.8359,  9.6079,\n",
      "         9.5722,  9.4740,  8.9855,  8.9699,  8.7508,  8.5830,  8.5609,  8.4860,\n",
      "         8.4041,  8.3704,  8.1654,  8.1614,  8.1177,  8.0486,  8.0423,  7.9372,\n",
      "         7.8615,  7.8257,  7.6522,  7.5705,  7.5472,  7.5389,  7.0732,  6.9774,\n",
      "         6.8641,  6.4830,  6.2049,  5.9481,  5.5675,  5.4550,  5.3111,  4.9761,\n",
      "         4.9019,  4.7422,  4.3426,  4.2749,  3.9946,  3.8948,  3.7753,  2.7652],\n",
      "       device='cuda:0')\n",
      "tensor([43.7792, 43.2289, 34.5597, 34.4835, 32.8142, 32.1508, 31.0064, 30.9996,\n",
      "        30.7821, 30.7487, 30.5007, 30.0212, 29.8183, 29.5353, 29.4366, 28.9485,\n",
      "        28.5650, 27.3728, 26.8157, 26.6773, 26.5779, 26.4751, 26.3993, 26.2684,\n",
      "        26.2048, 26.1568, 26.0609, 25.9858, 25.9048, 25.4524, 25.2070, 25.1691,\n",
      "        24.5995, 24.5918, 24.5187, 24.3286, 24.2104, 24.1975, 24.0234, 23.9813,\n",
      "        23.8734, 23.8321, 23.7447, 23.7065, 23.6539, 23.5197, 23.1906, 23.0420,\n",
      "        23.0128, 22.9099, 22.8979, 22.8801, 22.7654, 22.6653, 22.5767, 22.2671,\n",
      "        22.0109, 21.9574, 21.9068, 21.8587, 21.7444, 21.6994, 21.5839, 21.5830,\n",
      "        21.5395, 21.5044, 21.2060, 20.8560, 20.7047, 20.6968, 20.6490, 20.5765,\n",
      "        20.5434, 20.5293, 20.5292, 20.4505, 20.4280, 20.0982, 20.0704, 20.0630,\n",
      "        20.0267, 19.8691, 19.8435, 19.8186, 19.7481, 19.6940, 19.6772, 19.6743,\n",
      "        19.6371, 19.6183, 19.5975, 19.5934, 19.5540, 19.3142, 19.2791, 19.1776,\n",
      "        19.1688, 19.1628, 19.1600, 19.1367, 19.1278, 19.1221, 19.0951, 19.0294,\n",
      "        19.0256, 18.9316, 18.8529, 18.7810, 18.7481, 18.5959, 18.5247, 18.4926,\n",
      "        18.4101, 18.1732, 18.1211, 18.0922, 18.0732, 18.0730, 17.9178, 17.8641,\n",
      "        17.5835, 17.5582, 17.4643, 17.3325, 17.2526, 17.1642, 17.1091, 17.0764,\n",
      "        17.0386, 17.0238, 16.9994, 16.9901, 16.9774, 16.9484, 16.8724, 16.7883,\n",
      "        16.7762, 16.7029, 16.6582, 16.6196, 16.6111, 16.5072, 16.4622, 16.4326,\n",
      "        16.4150, 16.2025, 16.2002, 16.1903, 16.1784, 16.1542, 16.0741, 15.9824,\n",
      "        15.9626, 15.9597, 15.9447, 15.8352, 15.8190, 15.8103, 15.7823, 15.7056,\n",
      "        15.6602, 15.6428, 15.6366, 15.5266, 15.4878, 15.3941, 15.3498, 15.2771,\n",
      "        15.2338, 15.2260, 15.1962, 15.1416, 15.0749, 14.9683, 14.9088, 14.8943,\n",
      "        14.8287, 14.7241, 14.6913, 14.5393, 14.5056, 14.3791, 14.1503, 14.1469,\n",
      "        14.1227, 14.1100, 14.0082, 13.8893, 13.8644, 13.8165, 13.7066, 13.6412,\n",
      "        13.6406, 13.5992, 13.5948, 13.5696, 13.3985, 13.3459, 13.2688, 13.2652,\n",
      "        13.2652, 13.2391, 13.1912, 13.1691, 13.1498, 13.1273, 13.1188, 13.0760,\n",
      "        13.0302, 12.8913, 12.8791, 12.8725, 12.8681, 12.8537, 12.6864, 12.6529,\n",
      "        12.6477, 12.6350, 12.5780, 12.5281, 12.4773, 12.4622, 12.3871, 12.3413,\n",
      "        12.3139, 12.2648, 12.2502, 12.1393, 12.0620, 11.7808, 11.7768, 11.7382,\n",
      "        11.7266, 11.7160, 11.5666, 11.3613, 11.3015, 11.2030, 11.1984, 11.1922,\n",
      "        11.1772, 11.0760, 10.9548, 10.8968, 10.7363, 10.6883, 10.4852, 10.3974,\n",
      "        10.3816, 10.2133, 10.0318,  9.9053,  9.8557,  9.7153,  9.5422,  9.4624],\n",
      "       device='cuda:0')\n",
      "tensor([38.6672, 38.0830, 37.5954, 37.5340, 36.9157, 36.4289, 36.3151, 35.9255,\n",
      "        35.8624, 35.3290, 35.2350, 34.6435, 34.5842, 34.3365, 34.2892, 34.1212,\n",
      "        34.0672, 33.9353, 33.8897, 33.8861, 33.8212, 33.7973, 33.4583, 33.4339,\n",
      "        33.3550, 33.2240, 33.1358, 33.0085, 32.9827, 32.9476, 32.9155, 32.8833,\n",
      "        32.8504, 32.7887, 32.7851, 32.7815, 32.6289, 32.5499, 32.5464, 32.4484,\n",
      "        32.4134, 32.3389, 32.1165, 31.9899, 31.8844, 31.8135, 31.8005, 31.7843,\n",
      "        31.7793, 31.7525, 31.7012, 31.6979, 31.6489, 31.5474, 31.5205, 31.5071,\n",
      "        31.4784, 31.4631, 31.3989, 31.2253, 31.2133, 31.0805, 30.9882, 30.9692,\n",
      "        30.8418, 30.8338, 30.6955, 30.6857, 30.5785, 30.5615, 30.5452, 30.3554,\n",
      "        30.3320, 30.2999, 30.2730, 30.2708, 30.2635, 30.2631, 30.2184, 30.1734,\n",
      "        30.1691, 30.1532, 30.1349, 30.0282, 30.0131, 29.9664, 29.9452, 29.9451,\n",
      "        29.9360, 29.9260, 29.8213, 29.8109, 29.7616, 29.7188, 29.7059, 29.6759,\n",
      "        29.6600, 29.6010, 29.5292, 29.4742, 29.4531, 29.3648, 29.2786, 29.2255,\n",
      "        29.2190, 29.2116, 29.1971, 29.1716, 29.1099, 29.1055, 29.0884, 29.0866,\n",
      "        29.0074, 28.9694, 28.9263, 28.9034, 28.8666, 28.8605, 28.8588, 28.8317,\n",
      "        28.8272, 28.8210, 28.7358, 28.7009, 28.6147, 28.5715, 28.4754, 28.4096,\n",
      "        28.3436, 28.2912, 28.2616, 28.2437, 28.2240, 28.2225, 28.2164, 28.2030,\n",
      "        28.0360, 28.0323, 28.0310, 28.0294, 27.9638, 27.9613, 27.8996, 27.8765,\n",
      "        27.8739, 27.8454, 27.8120, 27.7498, 27.7314, 27.7232, 27.6997, 27.6796,\n",
      "        27.6738, 27.4973, 27.4915, 27.4711, 27.4565, 27.4409, 27.3834, 27.3782,\n",
      "        27.3672, 27.3180, 27.2992, 27.2522, 27.2368, 27.2216, 27.0300, 26.9952,\n",
      "        26.9809, 26.9509, 26.9043, 26.8570, 26.8550, 26.8535, 26.8312, 26.7327,\n",
      "        26.7306, 26.6307, 26.6079, 26.5644, 26.5477, 26.4621, 26.3634, 26.3459,\n",
      "        26.3080, 26.2834, 26.2725, 26.2383, 26.2044, 26.1818, 26.1639, 26.1612,\n",
      "        26.1406, 26.0329, 26.0028, 25.9449, 25.9396, 25.8634, 25.8023, 25.7537,\n",
      "        25.6224, 25.5851, 25.5802, 25.5427, 25.5189, 25.5144, 25.4548, 25.3931,\n",
      "        25.3789, 25.3679, 25.3642, 25.3521, 25.3497, 25.3444, 25.3202, 25.2489,\n",
      "        25.2279, 25.2220, 25.1530, 25.1281, 25.0761, 25.0416, 25.0120, 24.9916,\n",
      "        24.9338, 24.9255, 24.7823, 24.7603, 24.6599, 24.4915, 24.4177, 24.3988,\n",
      "        24.3305, 24.2686, 24.2557, 24.1645, 24.1537, 24.1496, 24.1193, 24.1083,\n",
      "        23.9813, 23.8258, 23.8181, 23.7043, 23.7010, 23.6873, 23.6026, 23.3822,\n",
      "        23.1311, 22.9266, 22.8699, 22.6409, 22.0999, 21.8443, 18.3518, 17.3845],\n",
      "       device='cuda:0')\n",
      "tensor([26.6835, 26.3936, 26.2842, 26.2376, 26.1797, 26.1240, 26.1090, 26.0479,\n",
      "        25.8924, 25.6306, 25.5789, 25.5097, 25.2546, 25.2335, 25.1059, 25.0635,\n",
      "        25.0566, 24.9942, 24.9930, 24.9244, 24.8583, 24.7047, 24.6868, 24.6514,\n",
      "        24.6211, 24.5808, 24.5434, 24.5075, 24.5073, 24.4058, 24.3556, 24.3391,\n",
      "        24.2610, 24.1326, 24.0599, 24.0545, 24.0062, 23.9848, 23.9841, 23.8147,\n",
      "        23.7297, 23.7078, 23.7034, 23.6830, 23.6700, 23.6569, 23.6531, 23.6515,\n",
      "        23.6468, 23.6249, 23.5846, 23.5108, 23.5022, 23.4553, 23.4415, 23.3971,\n",
      "        23.3196, 23.3068, 23.2812, 23.2368, 23.2259, 23.1506, 23.0994, 23.0853,\n",
      "        23.0438, 23.0313, 22.7730, 22.7138, 22.7046, 22.6051, 22.5707, 22.5566,\n",
      "        22.5557, 22.5497, 22.5430, 22.5233, 22.5004, 22.4924, 22.4485, 22.4485,\n",
      "        22.4092, 22.3442, 22.3361, 22.2478, 22.2166, 22.1882, 22.1431, 22.1194,\n",
      "        22.1016, 22.0893, 21.9795, 21.9743, 21.9609, 21.9603, 21.9491, 21.9332,\n",
      "        21.9228, 21.8996, 21.8817, 21.8719, 21.7721, 21.7689, 21.7097, 21.7080,\n",
      "        21.7066, 21.6924, 21.6913, 21.6769, 21.6725, 21.6213, 21.5882, 21.5528,\n",
      "        21.5358, 21.4928, 21.4579, 21.4070, 21.3823, 21.3676, 21.2587, 21.2011,\n",
      "        21.1681, 21.1628, 21.1366, 21.1161, 21.1031, 21.0562, 21.0472, 21.0470,\n",
      "        21.0249, 20.9947, 20.9802, 20.9756, 20.9476, 20.8857, 20.8259, 20.7429,\n",
      "        20.7187, 20.6591, 20.5995, 20.4793, 20.4231, 20.4092, 20.3941, 20.3464,\n",
      "        20.3425, 20.3136, 20.2813, 20.2755, 20.2560, 20.2530, 20.2491, 20.2077,\n",
      "        20.1941, 20.1513, 20.1504, 20.1219, 20.1012, 20.0920, 20.0684, 20.0259,\n",
      "        20.0247, 20.0200, 20.0126, 19.9478, 19.9474, 19.8729, 19.8645, 19.8546,\n",
      "        19.8250, 19.7771, 19.7703, 19.7656, 19.7425, 19.7353, 19.7257, 19.6542,\n",
      "        19.6448, 19.5861, 19.5007, 19.4419, 19.3321, 19.2582, 19.2237, 19.1984,\n",
      "        19.1396, 19.1303, 19.0992, 19.0825, 19.0747, 19.0437, 19.0383, 19.0128,\n",
      "        19.0119, 18.9752, 18.9480, 18.9185, 18.8753, 18.8462, 18.7765, 18.7152,\n",
      "        18.5730, 18.5373, 18.5280, 18.5234, 18.5116, 18.5006, 18.4842, 18.4668,\n",
      "        18.4571, 18.3168, 18.3007, 18.2852, 18.2696, 18.2312, 18.2292, 18.2172,\n",
      "        18.2127, 18.1986, 18.1272, 18.0546, 17.9773, 17.9617, 17.9320, 17.9258,\n",
      "        17.8729, 17.7835, 17.7318, 17.5052, 17.4568, 17.4040, 17.3974, 17.3898,\n",
      "        17.2747, 17.2635, 17.2248, 17.1727, 17.1645, 17.1107, 17.0517, 16.9378,\n",
      "        16.6899, 16.6830, 16.6170, 16.6014, 16.5844, 16.5375, 16.4860, 16.3460,\n",
      "        16.3391, 16.3284, 16.0219, 15.0700, 14.8920, 14.8070, 14.6958, 14.1923],\n",
      "       device='cuda:0')\n",
      "tensor([38.0239, 37.7814, 37.5915, 37.5311, 37.2375, 36.2238, 36.1191, 36.0961,\n",
      "        36.0899, 35.9503, 35.5710, 35.5502, 35.5452, 35.4437, 35.2376, 35.1788,\n",
      "        35.1535, 35.1017, 35.0350, 34.9469, 34.8635, 34.8012, 34.7540, 34.6388,\n",
      "        34.6357, 34.6296, 34.6187, 34.5501, 34.4233, 34.4219, 34.3298, 34.3089,\n",
      "        34.2856, 34.1815, 34.0054, 33.9185, 33.6555, 33.6343, 33.5874, 33.4051,\n",
      "        33.3780, 33.3105, 33.2416, 33.2071, 33.1267, 32.9439, 32.8941, 32.8210,\n",
      "        32.8107, 32.6999, 32.6474, 32.5097, 32.4871, 32.4821, 32.4593, 32.4011,\n",
      "        32.3871, 32.2720, 32.2513, 32.2055, 32.1673, 32.1528, 32.1319, 32.0142,\n",
      "        32.0045, 31.9851, 31.9690, 31.9564, 31.9508, 31.9459, 31.9082, 31.8915,\n",
      "        31.8847, 31.8222, 31.8107, 31.7853, 31.7411, 31.7344, 31.5128, 31.4837,\n",
      "        31.3970, 31.3894, 31.2719, 31.2444, 31.1902, 31.1859, 31.1836, 31.1634,\n",
      "        31.1527, 31.1526, 31.1087, 31.1001, 31.0717, 31.0597, 31.0230, 31.0121,\n",
      "        30.9417, 30.9404, 30.9363, 30.9101, 30.8517, 30.8512, 30.8472, 30.8226,\n",
      "        30.7930, 30.7737, 30.7678, 30.6199, 30.6149, 30.6014, 30.5904, 30.5632,\n",
      "        30.5605, 30.5409, 30.5331, 30.4519, 30.4253, 30.3930, 30.3766, 30.3623,\n",
      "        30.2828, 30.2603, 30.1784, 30.1591, 30.0893, 30.0598, 30.0585, 29.9873,\n",
      "        29.9743, 29.9725, 29.9218, 29.8452, 29.8089, 29.7965, 29.7951, 29.7911,\n",
      "        29.7628, 29.7044, 29.6518, 29.5788, 29.5326, 29.4273, 29.4167, 29.4150,\n",
      "        29.4066, 29.1839, 29.1685, 29.1312, 29.1094, 29.0919, 29.0898, 29.0828,\n",
      "        29.0467, 28.9038, 28.8240, 28.8191, 28.8094, 28.7818, 28.7513, 28.7437,\n",
      "        28.7379, 28.7246, 28.6805, 28.6733, 28.6276, 28.6035, 28.5994, 28.5263,\n",
      "        28.5259, 28.4883, 28.4329, 28.3963, 28.3727, 28.3055, 28.3013, 28.2783,\n",
      "        28.2496, 28.2331, 28.1748, 28.1588, 28.1129, 28.0984, 28.0173, 27.9462,\n",
      "        27.9376, 27.9206, 27.8939, 27.8585, 27.8411, 27.7978, 27.7432, 27.6937,\n",
      "        27.6541, 27.5831, 27.5701, 27.4841, 27.4111, 27.3767, 27.3494, 27.3425,\n",
      "        27.3321, 27.2174, 27.2147, 27.1785, 27.0628, 26.9253, 26.9016, 26.8931,\n",
      "        26.8883, 26.8820, 26.7250, 26.6110, 26.5142, 26.5115, 26.4901, 26.4877,\n",
      "        26.4200, 26.3842, 26.3642, 26.3135, 26.2950, 26.2074, 25.9211, 25.8588,\n",
      "        25.8222, 25.8028, 25.8019, 25.7954, 25.7588, 25.6653, 25.6620, 25.5592,\n",
      "        25.5349, 25.5006, 25.3961, 25.2772, 25.2753, 25.2319, 25.2070, 25.1571,\n",
      "        24.9306, 24.7800, 24.7446, 24.6495, 24.5652, 24.3991, 24.3959, 24.3350,\n",
      "        23.8094, 23.8007, 23.7402, 23.6606, 23.4680, 23.3701, 23.3257, 21.4190],\n",
      "       device='cuda:0')\n",
      "tensor([33.7138, 33.3734, 33.3063, 33.1566, 32.9157, 32.9134, 32.8275, 32.7686,\n",
      "        32.4748, 32.3872, 32.1133, 32.0403, 31.9708, 31.9376, 31.9198, 31.9078,\n",
      "        31.8595, 31.8581, 31.7710, 31.7303, 31.7093, 31.6424, 31.6385, 31.6263,\n",
      "        31.5273, 31.4895, 31.4343, 31.4220, 31.3958, 31.3579, 31.3304, 31.2846,\n",
      "        31.2821, 31.2723, 31.2642, 31.2369, 31.1959, 31.1596, 31.1475, 31.1163,\n",
      "        31.0922, 31.0773, 31.0767, 31.0166, 30.9842, 30.9727, 30.9484, 30.9472,\n",
      "        30.9081, 30.8893, 30.7609, 30.7263, 30.6310, 30.5846, 30.5600, 30.5575,\n",
      "        30.5210, 30.5144, 30.4379, 30.3756, 30.3719, 30.3617, 30.3344, 30.3114,\n",
      "        30.2538, 30.2279, 30.2269, 30.1850, 30.1646, 30.1449, 30.1283, 30.1031,\n",
      "        30.0380, 30.0224, 29.9703, 29.9189, 29.9177, 29.9007, 29.8678, 29.8642,\n",
      "        29.8485, 29.8231, 29.8207, 29.7839, 29.7585, 29.7403, 29.7115, 29.6809,\n",
      "        29.6794, 29.6628, 29.6560, 29.6552, 29.6415, 29.6394, 29.6300, 29.5931,\n",
      "        29.5556, 29.5033, 29.4919, 29.4218, 29.4106, 29.4082, 29.3981, 29.3390,\n",
      "        29.3175, 29.3162, 29.2685, 29.2683, 29.2581, 29.2418, 29.1493, 29.1335,\n",
      "        29.1229, 29.1221, 29.1140, 29.0753, 29.0664, 29.0477, 29.0090, 28.9953,\n",
      "        28.9612, 28.9545, 28.9284, 28.9121, 28.8908, 28.8850, 28.8848, 28.8630,\n",
      "        28.8523, 28.8324, 28.8225, 28.8169, 28.7640, 28.7631, 28.7145, 28.6324,\n",
      "        28.5945, 28.5738, 28.5681, 28.5551, 28.4243, 28.4130, 28.4091, 28.3773,\n",
      "        28.3280, 28.3161, 28.3079, 28.2869, 28.2326, 28.2190, 28.2114, 28.1743,\n",
      "        28.1690, 28.1242, 28.1146, 28.1034, 28.1006, 28.0759, 28.0195, 27.9735,\n",
      "        27.9609, 27.9515, 27.9340, 27.9260, 27.8923, 27.8700, 27.8267, 27.7955,\n",
      "        27.7838, 27.7731, 27.7700, 27.7504, 27.7260, 27.7184, 27.6985, 27.6871,\n",
      "        27.6132, 27.5774, 27.5517, 27.5130, 27.4887, 27.4395, 27.4181, 27.4063,\n",
      "        27.3765, 27.2898, 27.2661, 27.2482, 27.1919, 27.1808, 27.1726, 27.1477,\n",
      "        27.0975, 27.0689, 27.0674, 27.0272, 26.9883, 26.9507, 26.9082, 26.8599,\n",
      "        26.8525, 26.8315, 26.7564, 26.6971, 26.6695, 26.5669, 26.5626, 26.5367,\n",
      "        26.5261, 26.5194, 26.4982, 26.4792, 26.3431, 26.2978, 26.2337, 26.2245,\n",
      "        26.2135, 26.1652, 26.1329, 26.0938, 25.9875, 25.8533, 25.8509, 25.8425,\n",
      "        25.8313, 25.8283, 25.8232, 25.7324, 25.7207, 25.6638, 25.6624, 25.6369,\n",
      "        25.5849, 25.5026, 25.4826, 25.3664, 25.3317, 25.2779, 25.2679, 25.1126,\n",
      "        24.8695, 24.7619, 24.7420, 24.7105, 24.5928, 24.4468, 24.3207, 24.2402,\n",
      "        24.1036, 24.0409, 23.6704, 23.6136, 23.5723, 23.5641, 23.4861, 23.4108],\n",
      "       device='cuda:0')\n",
      "tensor([32.6869, 31.5509, 31.1702, 31.1266, 31.0334, 30.9573, 30.8032, 30.5803,\n",
      "        30.4395, 29.9995, 29.8999, 29.8988, 29.8330, 29.8163, 29.5341, 29.5246,\n",
      "        29.4008, 29.3127, 29.2960, 29.2957, 29.2334, 29.0121, 29.0057, 28.9542,\n",
      "        28.8963, 28.7502, 28.7016, 28.5727, 28.5007, 28.4965, 28.4803, 28.4374,\n",
      "        28.4057, 28.3969, 28.3601, 28.3290, 28.3261, 28.2470, 28.0966, 28.0555,\n",
      "        28.0481, 27.9423, 27.9235, 27.8990, 27.7000, 27.6453, 27.5581, 27.5535,\n",
      "        27.5487, 27.5302, 27.5164, 27.5072, 27.4624, 27.4066, 27.3857, 27.3797,\n",
      "        27.3541, 27.3515, 27.3225, 27.3196, 27.3037, 27.2775, 27.2703, 27.2703,\n",
      "        27.2567, 27.2213, 27.2046, 27.1982, 27.1932, 27.1499, 27.0661, 27.0325,\n",
      "        26.9968, 26.9949, 26.9854, 26.9660, 26.9445, 26.9378, 26.9188, 26.9002,\n",
      "        26.8911, 26.8773, 26.8595, 26.7836, 26.7776, 26.7290, 26.7101, 26.6855,\n",
      "        26.6456, 26.6449, 26.5920, 26.5441, 26.5439, 26.5418, 26.5404, 26.5389,\n",
      "        26.5350, 26.4810, 26.4563, 26.4388, 26.4240, 26.3879, 26.3817, 26.2944,\n",
      "        26.2670, 26.2625, 26.2338, 26.2281, 26.1176, 26.1167, 26.0894, 26.0805,\n",
      "        25.9831, 25.9677, 25.9572, 25.9366, 25.8993, 25.8902, 25.8555, 25.8154,\n",
      "        25.8035, 25.7768, 25.7757, 25.7673, 25.7608, 25.7397, 25.7376, 25.7296,\n",
      "        25.7207, 25.7015, 25.6271, 25.5620, 25.5378, 25.5213, 25.4838, 25.4837,\n",
      "        25.4591, 25.4377, 25.4206, 25.3987, 25.3573, 25.3467, 25.3209, 25.2986,\n",
      "        25.2963, 25.2900, 25.2436, 25.2406, 25.2401, 25.2346, 25.2288, 25.1820,\n",
      "        25.1590, 25.1517, 25.1253, 25.1129, 25.0920, 25.0344, 25.0023, 24.9695,\n",
      "        24.9624, 24.9368, 24.8373, 24.8241, 24.8214, 24.8089, 24.8045, 24.7631,\n",
      "        24.7629, 24.7572, 24.6990, 24.6987, 24.6793, 24.6553, 24.6447, 24.5660,\n",
      "        24.5231, 24.4649, 24.3963, 24.3872, 24.3825, 24.3786, 24.3236, 24.2988,\n",
      "        24.2412, 24.2245, 24.2084, 24.1284, 23.9354, 23.9353, 23.9115, 23.8971,\n",
      "        23.8307, 23.8016, 23.7705, 23.7487, 23.7483, 23.7345, 23.6806, 23.6082,\n",
      "        23.6032, 23.5836, 23.5774, 23.5384, 23.5094, 23.3188, 23.3141, 23.3113,\n",
      "        23.2695, 23.2396, 23.2284, 23.1965, 23.0224, 23.0063, 22.9417, 22.9144,\n",
      "        22.8903, 22.8722, 22.8688, 22.6741, 22.6722, 22.6691, 22.6665, 22.6660,\n",
      "        22.6165, 22.5455, 22.5015, 22.4648, 22.4631, 22.3746, 22.2849, 22.1909,\n",
      "        22.1775, 22.1250, 22.0545, 21.8518, 21.6134, 21.6033, 21.5328, 21.4804,\n",
      "        21.4670, 21.2596, 21.2054, 21.1460, 21.0728, 21.0432, 21.0243, 20.9038,\n",
      "        20.8122, 20.7787, 20.7364, 20.5587, 19.6820, 19.6698, 19.4922, 18.9219],\n",
      "       device='cuda:0')\n",
      "tensor([45.2439, 44.6278, 43.3469, 42.7397, 42.4049, 42.0522, 41.7015, 41.5161,\n",
      "        41.3255, 41.2949, 41.2654, 40.8593, 40.8187, 40.5934, 40.4966, 40.3468,\n",
      "        40.2488, 40.1953, 40.1669, 40.0773, 40.0725, 40.0346, 39.9824, 39.9210,\n",
      "        39.9185, 39.8923, 39.8760, 39.7596, 39.7193, 39.6595, 39.6522, 39.4581,\n",
      "        39.3850, 39.2653, 39.2010, 39.1903, 39.1794, 39.1481, 39.1409, 39.0742,\n",
      "        39.0461, 39.0279, 38.9134, 38.8556, 38.8452, 38.8120, 38.7682, 38.7136,\n",
      "        38.6804, 38.6730, 38.6609, 38.6579, 38.5997, 38.5587, 38.4965, 38.4949,\n",
      "        38.4938, 38.4681, 38.3609, 38.3525, 38.3398, 38.2712, 38.2318, 38.1692,\n",
      "        38.1689, 38.1569, 38.1104, 38.0989, 38.0330, 38.0302, 38.0168, 37.9824,\n",
      "        37.9823, 37.9392, 37.9278, 37.8814, 37.8353, 37.7865, 37.7066, 37.7017,\n",
      "        37.6669, 37.6083, 37.6057, 37.5893, 37.5892, 37.5406, 37.5375, 37.5362,\n",
      "        37.5323, 37.5284, 37.5213, 37.5174, 37.4567, 37.4451, 37.4203, 37.4179,\n",
      "        37.4028, 37.3697, 37.3125, 37.2546, 37.2191, 37.1080, 37.0472, 36.9779,\n",
      "        36.9068, 36.9056, 36.9027, 36.8893, 36.7904, 36.6787, 36.6531, 36.6500,\n",
      "        36.6435, 36.6007, 36.5727, 36.5101, 36.5091, 36.4503, 36.4367, 36.4016,\n",
      "        36.3871, 36.3598, 36.3462, 36.3119, 36.2824, 36.2817, 36.2758, 36.2438,\n",
      "        36.2369, 36.1608, 36.1253, 36.0933, 36.0729, 36.0417, 36.0192, 35.9779,\n",
      "        35.9717, 35.9365, 35.9156, 35.8695, 35.8270, 35.7869, 35.7809, 35.7694,\n",
      "        35.7483, 35.7391, 35.7204, 35.6864, 35.6827, 35.6659, 35.6618, 35.5799,\n",
      "        35.5437, 35.5249, 35.4919, 35.4556, 35.4010, 35.3790, 35.3527, 35.3415,\n",
      "        35.3312, 35.3155, 35.2971, 35.2871, 35.2827, 35.2323, 35.2155, 35.1664,\n",
      "        35.1395, 35.1062, 35.1039, 35.1035, 35.0055, 34.9817, 34.9745, 34.9545,\n",
      "        34.9517, 34.9485, 34.9350, 34.9221, 34.9190, 34.8906, 34.8854, 34.8082,\n",
      "        34.7863, 34.7370, 34.6384, 34.5658, 34.5301, 34.5001, 34.4589, 34.4543,\n",
      "        34.4484, 34.4424, 34.3701, 34.3307, 34.2742, 34.2648, 34.2544, 34.2362,\n",
      "        34.2306, 34.1789, 34.1732, 34.1644, 34.1251, 34.0903, 34.0848, 34.0738,\n",
      "        33.9914, 33.9342, 33.9317, 33.8970, 33.8599, 33.7770, 33.7726, 33.7544,\n",
      "        33.6804, 33.6194, 33.5710, 33.5691, 33.5532, 33.5100, 33.4619, 33.4196,\n",
      "        33.3125, 33.2660, 33.2548, 33.0806, 32.9818, 32.9210, 32.9073, 32.8777,\n",
      "        32.7727, 32.6816, 32.6597, 32.6315, 32.4950, 32.4107, 32.2991, 32.2824,\n",
      "        32.2662, 32.2177, 32.2155, 32.0475, 31.9615, 31.6813, 31.6779, 31.5385,\n",
      "        31.5267, 31.3045, 31.1686, 30.8915, 30.3731, 29.6219, 29.4553, 29.4364],\n",
      "       device='cuda:0')\n",
      "tensor([42.1417, 42.0675, 42.0671, 41.9790, 39.8013, 39.6585, 39.5037, 39.3553,\n",
      "        39.2542, 39.1842, 38.8434, 38.7332, 38.7313, 38.4040, 38.3000, 38.2386,\n",
      "        38.2098, 38.1386, 38.0318, 37.9703, 37.9568, 37.9239, 37.8639, 37.7764,\n",
      "        37.7560, 37.6010, 37.5823, 37.5460, 37.5029, 37.3741, 37.3550, 37.3351,\n",
      "        37.3035, 37.2777, 37.2256, 37.1982, 37.1516, 37.1083, 37.0597, 37.0210,\n",
      "        36.9587, 36.9550, 36.9108, 36.8981, 36.8835, 36.8487, 36.8455, 36.7064,\n",
      "        36.7046, 36.6995, 36.6594, 36.6481, 36.6161, 36.6146, 36.6133, 36.6042,\n",
      "        36.5693, 36.5474, 36.5267, 36.5010, 36.4636, 36.4469, 36.4049, 36.4029,\n",
      "        36.3635, 36.3136, 36.3005, 36.1847, 36.1364, 36.1284, 36.1164, 36.1059,\n",
      "        36.0264, 35.9572, 35.9532, 35.8792, 35.8729, 35.8514, 35.8187, 35.7995,\n",
      "        35.7877, 35.7585, 35.7383, 35.7335, 35.7323, 35.6952, 35.6870, 35.6795,\n",
      "        35.6680, 35.6245, 35.5938, 35.5859, 35.5325, 35.5081, 35.4968, 35.4596,\n",
      "        35.4298, 35.4025, 35.3679, 35.3437, 35.3279, 35.3092, 35.2629, 35.2318,\n",
      "        35.1750, 35.1655, 35.1202, 35.1123, 35.0961, 35.0916, 35.0274, 35.0242,\n",
      "        34.9728, 34.9591, 34.9191, 34.8956, 34.8554, 34.8527, 34.8379, 34.7918,\n",
      "        34.7766, 34.7619, 34.7278, 34.7242, 34.6824, 34.6346, 34.6116, 34.6011,\n",
      "        34.5668, 34.5471, 34.5221, 34.5189, 34.5140, 34.5065, 34.5000, 34.4893,\n",
      "        34.4682, 34.4537, 34.4489, 34.4397, 34.3569, 34.3400, 34.3366, 34.3307,\n",
      "        34.3298, 34.3279, 34.3247, 34.2981, 34.2806, 34.2230, 34.2114, 34.1668,\n",
      "        34.0951, 34.0562, 33.9432, 33.9406, 33.9171, 33.8484, 33.8159, 33.8093,\n",
      "        33.7922, 33.7871, 33.7771, 33.7426, 33.7358, 33.7352, 33.6708, 33.6604,\n",
      "        33.6501, 33.6276, 33.6242, 33.6220, 33.5993, 33.5705, 33.5649, 33.5536,\n",
      "        33.5526, 33.5238, 33.5098, 33.4495, 33.3625, 33.3286, 33.3206, 33.2922,\n",
      "        33.2772, 33.2367, 33.2218, 33.2134, 33.1955, 33.1930, 33.1478, 33.1387,\n",
      "        33.1054, 33.0975, 33.0391, 33.0335, 33.0327, 32.9841, 32.9094, 32.8825,\n",
      "        32.8817, 32.8745, 32.8693, 32.8675, 32.8612, 32.7996, 32.7659, 32.6851,\n",
      "        32.6735, 32.6405, 32.6400, 32.6238, 32.5165, 32.3069, 32.2888, 32.2757,\n",
      "        32.2409, 32.2136, 32.2002, 32.1966, 32.1868, 32.1649, 32.1314, 32.1173,\n",
      "        32.0983, 31.9634, 31.9304, 31.9198, 31.8756, 31.7666, 31.7338, 31.7282,\n",
      "        31.7045, 31.6356, 31.5928, 31.5825, 31.5199, 31.4621, 31.4501, 31.4130,\n",
      "        31.2247, 31.1028, 31.0935, 31.0574, 30.9776, 30.9755, 30.9383, 30.9087,\n",
      "        30.8067, 30.8017, 30.7350, 30.1612, 29.2896, 28.0639, 27.4032, 27.1695],\n",
      "       device='cuda:0')\n",
      "tensor([36.0429, 35.5257, 35.1925, 34.9021, 34.8460, 34.7887, 34.2718, 34.2439,\n",
      "        33.7818, 33.7606, 33.5865, 33.4109, 33.3931, 33.3224, 33.2972, 33.1373,\n",
      "        33.1301, 33.0679, 33.0625, 33.0497, 33.0338, 32.9843, 32.9300, 32.9074,\n",
      "        32.7737, 32.7049, 32.6352, 32.5802, 32.4488, 32.4133, 32.4079, 32.3972,\n",
      "        32.3871, 32.3811, 32.3170, 32.2689, 32.0296, 32.0163, 31.9968, 31.8876,\n",
      "        31.8572, 31.8490, 31.8099, 31.8061, 31.7924, 31.7072, 31.6789, 31.5807,\n",
      "        31.5596, 31.4590, 31.4413, 31.3693, 31.3691, 31.3446, 31.3331, 31.3282,\n",
      "        31.3221, 31.3039, 31.3035, 31.2930, 31.2494, 31.2127, 31.1979, 31.0568,\n",
      "        31.0435, 30.9477, 30.9350, 30.9183, 30.9122, 30.8818, 30.8777, 30.8709,\n",
      "        30.8698, 30.8327, 30.8143, 30.8085, 30.7946, 30.7894, 30.7841, 30.7779,\n",
      "        30.7711, 30.7577, 30.7326, 30.7306, 30.6843, 30.6510, 30.6457, 30.6380,\n",
      "        30.5975, 30.5778, 30.5722, 30.5705, 30.5585, 30.5494, 30.5126, 30.5028,\n",
      "        30.4991, 30.3858, 30.3847, 30.3820, 30.3510, 30.3420, 30.3022, 30.2646,\n",
      "        30.1801, 30.1714, 30.1479, 30.1454, 30.1419, 30.1345, 30.1239, 30.1174,\n",
      "        30.0835, 30.0833, 30.0813, 30.0695, 30.0664, 29.9893, 29.9697, 29.9644,\n",
      "        29.9512, 29.9408, 29.9374, 29.9216, 29.9118, 29.8670, 29.8555, 29.8488,\n",
      "        29.8264, 29.7286, 29.7204, 29.7172, 29.6457, 29.6368, 29.5963, 29.5726,\n",
      "        29.5192, 29.5100, 29.5016, 29.4875, 29.4495, 29.4438, 29.4428, 29.3923,\n",
      "        29.3839, 29.3809, 29.3777, 29.3669, 29.3331, 29.3152, 29.3082, 29.2820,\n",
      "        29.2753, 29.2440, 29.2151, 29.2139, 29.1703, 29.1548, 29.1475, 29.1432,\n",
      "        29.1375, 29.1156, 29.1006, 29.0060, 28.9911, 28.9772, 28.9628, 28.9265,\n",
      "        28.8849, 28.8803, 28.8442, 28.8395, 28.8342, 28.8032, 28.7956, 28.7952,\n",
      "        28.7376, 28.7349, 28.7243, 28.7157, 28.6811, 28.6765, 28.5353, 28.4860,\n",
      "        28.4609, 28.4555, 28.4366, 28.4143, 28.3820, 28.3795, 28.3267, 28.3236,\n",
      "        28.3203, 28.3190, 28.3124, 28.3117, 28.2866, 28.2377, 28.1535, 28.1301,\n",
      "        28.0805, 28.0764, 28.0418, 28.0282, 27.9900, 27.9428, 27.9389, 27.8757,\n",
      "        27.8636, 27.8355, 27.7657, 27.7593, 27.7102, 27.6390, 27.6311, 27.6224,\n",
      "        27.5585, 27.5300, 27.5224, 27.4617, 27.3911, 27.3603, 27.3378, 27.3157,\n",
      "        27.3133, 27.2888, 27.2087, 27.1482, 27.0895, 27.0449, 27.0394, 26.9952,\n",
      "        26.9588, 26.9285, 26.8905, 26.8761, 26.7910, 26.7551, 26.7457, 26.6487,\n",
      "        26.5780, 26.5621, 26.5001, 26.1140, 26.0978, 26.0634, 25.5727, 25.5538,\n",
      "        25.4956, 25.4485, 25.3930, 25.2332, 24.9553, 24.8205, 24.1635, 23.0503],\n",
      "       device='cuda:0')\n",
      "tensor([49.3272, 47.6340, 47.2063, 46.9294, 46.8830, 46.7985, 46.4931, 46.1310,\n",
      "        45.7709, 45.6294, 45.6293, 45.5436, 45.5002, 45.3201, 45.3154, 44.9723,\n",
      "        44.9198, 44.8508, 44.8077, 44.7916, 44.7524, 44.7318, 44.6496, 44.6151,\n",
      "        44.5300, 44.5185, 44.4632, 44.0455, 44.0307, 44.0299, 44.0184, 44.0121,\n",
      "        43.9313, 43.8501, 43.8275, 43.7936, 43.7920, 43.7918, 43.7155, 43.6914,\n",
      "        43.5375, 43.5194, 43.5153, 43.5038, 43.4889, 43.4839, 43.4154, 43.3912,\n",
      "        43.3881, 43.3058, 43.2155, 43.1929, 43.1848, 43.1461, 43.1273, 43.0793,\n",
      "        43.0377, 42.9884, 42.8786, 42.8620, 42.8422, 42.8271, 42.8066, 42.7730,\n",
      "        42.6654, 42.6359, 42.6353, 42.6224, 42.5418, 42.5361, 42.4882, 42.4751,\n",
      "        42.4345, 42.4137, 42.3581, 42.3026, 42.3002, 42.2516, 42.2489, 42.1835,\n",
      "        42.1762, 42.1590, 42.1247, 42.0053, 41.9656, 41.9335, 41.8743, 41.8720,\n",
      "        41.8384, 41.8048, 41.7494, 41.7103, 41.6630, 41.6439, 41.6236, 41.6219,\n",
      "        41.5919, 41.5606, 41.5584, 41.5064, 41.3973, 41.3590, 41.2972, 41.2416,\n",
      "        41.2394, 41.2224, 41.2197, 41.1934, 41.1521, 41.1459, 41.1393, 41.1367,\n",
      "        41.1339, 41.1287, 41.0847, 41.0784, 40.9496, 40.9270, 40.8517, 40.8083,\n",
      "        40.8003, 40.6950, 40.6544, 40.6521, 40.6237, 40.6026, 40.5965, 40.5921,\n",
      "        40.5488, 40.5421, 40.5229, 40.4738, 40.4192, 40.3944, 40.3373, 40.2944,\n",
      "        40.2820, 40.2745, 40.2635, 40.2357, 40.2191, 40.1898, 40.1497, 40.1392,\n",
      "        40.1325, 40.1321, 40.0550, 40.0402, 40.0062, 39.9965, 39.9583, 39.9315,\n",
      "        39.8996, 39.8481, 39.8176, 39.8154, 39.7829, 39.7754, 39.7587, 39.7458,\n",
      "        39.6967, 39.6932, 39.6511, 39.6296, 39.6146, 39.5310, 39.5102, 39.5039,\n",
      "        39.4638, 39.4378, 39.4220, 39.3772, 39.3675, 39.3383, 39.3160, 39.2760,\n",
      "        39.2502, 39.1622, 39.1274, 39.1270, 39.1086, 39.0732, 39.0683, 39.0224,\n",
      "        38.9961, 38.9581, 38.8024, 38.7991, 38.7591, 38.7517, 38.6577, 38.6534,\n",
      "        38.5209, 38.5183, 38.4958, 38.3478, 38.3277, 38.3048, 38.3029, 38.2108,\n",
      "        38.1541, 38.1270, 38.1136, 38.0199, 38.0064, 37.9291, 37.9103, 37.8409,\n",
      "        37.8006, 37.7286, 37.7007, 37.6846, 37.6684, 37.5509, 37.5196, 37.4893,\n",
      "        37.4432, 37.4399, 37.4284, 37.4191, 37.3727, 37.3227, 37.2440, 37.0172,\n",
      "        37.0087, 36.9417, 36.8646, 36.8528, 36.8475, 36.8257, 36.8185, 36.8071,\n",
      "        36.7335, 36.4005, 36.3462, 36.1632, 36.0320, 35.9554, 35.8450, 35.7720,\n",
      "        35.7146, 35.6757, 35.6091, 35.5617, 35.5178, 35.4417, 35.4263, 35.2826,\n",
      "        34.9398, 34.9366, 34.9295, 34.8471, 33.8771, 33.6278, 32.5558, 30.6628],\n",
      "       device='cuda:0')\n",
      "tensor([51.2681, 50.2029, 49.8278, 49.1588, 48.9479, 48.4470, 48.1461, 47.8226,\n",
      "        47.5703, 47.5215, 47.4703, 47.4484, 47.4131, 47.3087, 47.2682, 47.1398,\n",
      "        46.8592, 46.7069, 46.6980, 46.5863, 46.5855, 46.4608, 46.3938, 46.2195,\n",
      "        46.2021, 46.0959, 46.0926, 46.0685, 46.0275, 46.0199, 45.9085, 45.8565,\n",
      "        45.8027, 45.7946, 45.7924, 45.6760, 45.6284, 45.5684, 45.5320, 45.4884,\n",
      "        45.4040, 45.4016, 45.3696, 45.3586, 45.3225, 45.2812, 45.2154, 45.1693,\n",
      "        45.1209, 45.0703, 45.0585, 45.0427, 45.0308, 45.0027, 44.9991, 44.9867,\n",
      "        44.9762, 44.9660, 44.8797, 44.8035, 44.7232, 44.7167, 44.6992, 44.6608,\n",
      "        44.6038, 44.5514, 44.4763, 44.4589, 44.4513, 44.3995, 44.3230, 44.3153,\n",
      "        44.2596, 44.1913, 44.1810, 44.1265, 44.0990, 44.0767, 44.0490, 44.0422,\n",
      "        44.0297, 43.9855, 43.9853, 43.9836, 43.9650, 43.9022, 43.8468, 43.8397,\n",
      "        43.7801, 43.6787, 43.6749, 43.6623, 43.6555, 43.5734, 43.5383, 43.4722,\n",
      "        43.4644, 43.4280, 43.4080, 43.3872, 43.3642, 43.3331, 43.3102, 43.2957,\n",
      "        43.2406, 43.2129, 43.1849, 43.1336, 43.0084, 42.9774, 42.9727, 42.9271,\n",
      "        42.8977, 42.8976, 42.8759, 42.8419, 42.7945, 42.7576, 42.7561, 42.7129,\n",
      "        42.6898, 42.6151, 42.5610, 42.5549, 42.5288, 42.4952, 42.4874, 42.4675,\n",
      "        42.4675, 42.4443, 42.4353, 42.4296, 42.4046, 42.3696, 42.2688, 42.2333,\n",
      "        42.2264, 42.2237, 42.2109, 42.1732, 42.0862, 42.0590, 41.9764, 41.9523,\n",
      "        41.9465, 41.9251, 41.8701, 41.8596, 41.8255, 41.7838, 41.7720, 41.7610,\n",
      "        41.7397, 41.6890, 41.6676, 41.6244, 41.5935, 41.5882, 41.5839, 41.5660,\n",
      "        41.5646, 41.5427, 41.4627, 41.4017, 41.3649, 41.3319, 41.3076, 41.2910,\n",
      "        41.2594, 41.1914, 41.1786, 41.1416, 41.1214, 41.0971, 41.0582, 40.9931,\n",
      "        40.9547, 40.9395, 40.9130, 40.8486, 40.8446, 40.8178, 40.8162, 40.8046,\n",
      "        40.7567, 40.7538, 40.7528, 40.7304, 40.7212, 40.7019, 40.6119, 40.6104,\n",
      "        40.5780, 40.5349, 40.4994, 40.4082, 40.3639, 40.2865, 40.2105, 40.2001,\n",
      "        40.1978, 40.0943, 40.0835, 40.0801, 40.0625, 40.0404, 39.9363, 39.9249,\n",
      "        39.8332, 39.8174, 39.7217, 39.6912, 39.6889, 39.6662, 39.6123, 39.5710,\n",
      "        39.4861, 39.4709, 39.4167, 39.2334, 38.9939, 38.9733, 38.9191, 38.9099,\n",
      "        38.7670, 38.7340, 38.6992, 38.5590, 38.5567, 38.4688, 38.3882, 38.3745,\n",
      "        38.3381, 38.3205, 38.2902, 38.2546, 38.1530, 38.0712, 38.0568, 37.9445,\n",
      "        37.9101, 37.6304, 37.3370, 37.2974, 36.9548, 36.7394, 36.6160, 36.3469,\n",
      "        36.2692, 36.2014, 35.8529, 35.3939, 35.2509, 35.2071, 34.3410, 33.4430],\n",
      "       device='cuda:0')\n",
      "tensor([46.2202, 45.9126, 45.1598, 44.6417, 44.5983, 44.5668, 44.5159, 43.7796,\n",
      "        43.6613, 43.6357, 43.6339, 43.3665, 43.2708, 43.1376, 43.1159, 43.0594,\n",
      "        43.0512, 42.9237, 42.7893, 42.7541, 42.7120, 42.6040, 42.5070, 42.4873,\n",
      "        42.4554, 42.4520, 42.4276, 42.4061, 42.3716, 42.0550, 42.0474, 42.0131,\n",
      "        42.0124, 41.9064, 41.9059, 41.9029, 41.8738, 41.7449, 41.7242, 41.6254,\n",
      "        41.6162, 41.5540, 41.5506, 41.5149, 41.4836, 41.4696, 41.4240, 41.4110,\n",
      "        41.3868, 41.3788, 41.2981, 41.2747, 41.2746, 41.1948, 41.1938, 41.1930,\n",
      "        41.1589, 41.1338, 41.1330, 41.1053, 41.1029, 41.1024, 41.0793, 41.0375,\n",
      "        40.9730, 40.9714, 40.9276, 40.8870, 40.8576, 40.8260, 40.7793, 40.7703,\n",
      "        40.7603, 40.7517, 40.7330, 40.7224, 40.6652, 40.6615, 40.6502, 40.5655,\n",
      "        40.5555, 40.5276, 40.4568, 40.4344, 40.3322, 40.3063, 40.2424, 40.1937,\n",
      "        40.1711, 40.1571, 40.1396, 40.0925, 40.0886, 40.0839, 40.0791, 40.0780,\n",
      "        40.0463, 40.0389, 40.0096, 39.9998, 39.9810, 39.9501, 39.9385, 39.9349,\n",
      "        39.8993, 39.8806, 39.8487, 39.8400, 39.8279, 39.7625, 39.7553, 39.7088,\n",
      "        39.7013, 39.6787, 39.6192, 39.6107, 39.5718, 39.5405, 39.5131, 39.4740,\n",
      "        39.4734, 39.4600, 39.4313, 39.4210, 39.4086, 39.4034, 39.4000, 39.3755,\n",
      "        39.3434, 39.2901, 39.2626, 39.2563, 39.2267, 39.2117, 39.1894, 39.1876,\n",
      "        39.1836, 39.1836, 39.1580, 39.1064, 39.0683, 39.0498, 39.0353, 38.9907,\n",
      "        38.9891, 38.9602, 38.9150, 38.8925, 38.8405, 38.8346, 38.8234, 38.7594,\n",
      "        38.7173, 38.6924, 38.6723, 38.6499, 38.5823, 38.5523, 38.5411, 38.5217,\n",
      "        38.4710, 38.4709, 38.4632, 38.4579, 38.4404, 38.4273, 38.4151, 38.4132,\n",
      "        38.3976, 38.3947, 38.3930, 38.3260, 38.2516, 38.2355, 38.2285, 38.2196,\n",
      "        38.1950, 38.1686, 38.0462, 38.0321, 38.0133, 37.9690, 37.8525, 37.8385,\n",
      "        37.8310, 37.8198, 37.7292, 37.7281, 37.7159, 37.6890, 37.6581, 37.6428,\n",
      "        37.6204, 37.5702, 37.5626, 37.4647, 37.4644, 37.4348, 37.3506, 37.3281,\n",
      "        37.3101, 37.2980, 37.2308, 37.2137, 37.1318, 37.1258, 37.1051, 37.1014,\n",
      "        37.0968, 37.0746, 37.0649, 37.0356, 37.0010, 36.9680, 36.8663, 36.8421,\n",
      "        36.7827, 36.7374, 36.6498, 36.6100, 36.5955, 36.5345, 36.4515, 36.4510,\n",
      "        36.4320, 36.3612, 36.3588, 36.3260, 36.3192, 36.3031, 36.1366, 36.0602,\n",
      "        36.0516, 35.9871, 35.9428, 35.8640, 35.8244, 35.8059, 35.7181, 35.6863,\n",
      "        35.6766, 35.4940, 35.3046, 35.2097, 35.1879, 35.0520, 34.9824, 34.8319,\n",
      "        34.7524, 34.7483, 34.6080, 34.5519, 34.5067, 34.4671, 33.9855, 33.1352],\n",
      "       device='cuda:0')\n",
      "tensor([71.8334, 71.7637, 70.6612, 69.2167, 69.0902, 68.8047, 68.7511, 68.4455,\n",
      "        68.3817, 68.2849, 68.1678, 68.1402, 68.0499, 67.8673, 67.8142, 67.5985,\n",
      "        67.4378, 67.3143, 67.2682, 67.1147, 66.9237, 66.8888, 66.8800, 66.8339,\n",
      "        66.7961, 66.6724, 66.5981, 66.4957, 66.4322, 66.4322, 66.3263, 66.0510,\n",
      "        66.0369, 65.9729, 65.9102, 65.8554, 65.8411, 65.7066, 65.6977, 65.6647,\n",
      "        65.5345, 65.3680, 65.2362, 65.2187, 65.1809, 65.1483, 65.0930, 65.0801,\n",
      "        65.0399, 65.0366, 64.9426, 64.8028, 64.7960, 64.6464, 64.6177, 64.6023,\n",
      "        64.5649, 64.4871, 64.4732, 64.4071, 64.4056, 64.3620, 64.3329, 64.3022,\n",
      "        64.2937, 64.2881, 64.2688, 64.1831, 64.0958, 64.0956, 64.0726, 64.0173,\n",
      "        63.9999, 63.9781, 63.9131, 63.9087, 63.8898, 63.8312, 63.8265, 63.7779,\n",
      "        63.7727, 63.6983, 63.6829, 63.6815, 63.5708, 63.5424, 63.5269, 63.5245,\n",
      "        63.4963, 63.4885, 63.4758, 63.4554, 63.4461, 63.3228, 63.3055, 63.2024,\n",
      "        63.1924, 63.1455, 63.1298, 63.0750, 63.0431, 62.9943, 62.9772, 62.9146,\n",
      "        62.9049, 62.8721, 62.7041, 62.6468, 62.5977, 62.5785, 62.5669, 62.5570,\n",
      "        62.5556, 62.5192, 62.5139, 62.4902, 62.4881, 62.4629, 62.4626, 62.4625,\n",
      "        62.4492, 62.4224, 62.4003, 62.2815, 62.2808, 62.2756, 62.2577, 62.2492,\n",
      "        62.2320, 62.2245, 62.1939, 62.1911, 62.1355, 62.0403, 62.0379, 62.0156,\n",
      "        61.8753, 61.8671, 61.8612, 61.8345, 61.8238, 61.7549, 61.7491, 61.7380,\n",
      "        61.6963, 61.6892, 61.6516, 61.6497, 61.6402, 61.6279, 61.6191, 61.6128,\n",
      "        61.6055, 61.5713, 61.5299, 61.4984, 61.4575, 61.4496, 61.4120, 61.4038,\n",
      "        61.3961, 61.3822, 61.3381, 61.2955, 61.2706, 61.2153, 61.1750, 61.1257,\n",
      "        60.9973, 60.9932, 60.9713, 60.9465, 60.8761, 60.8228, 60.7923, 60.7862,\n",
      "        60.7498, 60.7447, 60.7388, 60.7208, 60.7117, 60.7043, 60.7005, 60.6387,\n",
      "        60.6166, 60.6162, 60.4776, 60.4509, 60.4310, 60.3991, 60.3694, 60.3301,\n",
      "        60.1580, 60.1318, 60.1293, 60.0815, 60.0810, 59.9936, 59.8582, 59.8535,\n",
      "        59.7802, 59.7235, 59.6834, 59.6624, 59.6267, 59.4612, 59.4447, 59.3785,\n",
      "        59.3246, 59.3139, 59.2907, 59.2628, 59.2286, 59.2149, 59.1903, 59.1894,\n",
      "        58.9877, 58.9506, 58.6973, 58.6485, 58.6291, 58.5662, 58.3449, 58.3412,\n",
      "        58.2574, 58.2541, 58.2476, 58.2368, 58.1250, 57.9768, 57.9525, 57.8346,\n",
      "        57.6732, 57.6583, 57.5866, 57.4805, 57.4512, 57.4109, 57.3987, 57.3537,\n",
      "        57.3410, 56.7638, 56.6250, 56.5423, 56.2203, 55.8196, 55.6963, 55.6878,\n",
      "        55.5403, 55.5146, 55.5078, 55.3367, 54.8624, 54.8403, 53.7901, 51.8153],\n",
      "       device='cuda:0')\n",
      "tensor([ 89.8362,  89.8563,  95.2335,  89.0963,  95.6670,  94.7886,  91.0336,\n",
      "         92.0686,  95.5118,  95.9572,  94.4242,  90.8111,  88.8177,  88.3648,\n",
      "         94.5348,  92.5438, 101.5874,  87.1652,  96.8310,  91.3544,  91.4994,\n",
      "         90.5074,  97.1234,  90.7107,  97.1893,  90.7229,  91.4701,  89.2359,\n",
      "         97.6245,  95.1741,  99.5386,  95.4568,  93.6740,  86.4724,  97.2877,\n",
      "        105.1522,  94.0085,  92.8619,  86.4961,  89.6461, 104.1752,  88.1646,\n",
      "         99.0209,  92.1080,  86.2642,  90.9150,  88.2852,  97.5225,  91.7332,\n",
      "         94.6147,  88.6523,  94.2516,  89.3493,  95.5779,  92.4052,  89.7137,\n",
      "         96.7429,  90.8308,  96.0332,  99.6965,  98.1015,  96.2556,  91.4348,\n",
      "         92.3578,  85.9483,  93.9044,  90.0541, 104.0008,  91.4167,  95.7194,\n",
      "        102.6082,  90.0602, 102.7929,  83.6980, 100.0225,  95.1152,  95.8389,\n",
      "         92.4033,  86.7938,  95.9765,  96.8414,  94.5979,  93.0619,  95.0195,\n",
      "         92.3061,  88.7892,  95.1242,  93.9319, 101.2353,  86.5530,  98.9135,\n",
      "         94.5978,  94.1974,  93.8555,  96.4509,  90.3565,  92.7474,  88.7202,\n",
      "         90.7131,  90.3962,  94.3920,  89.6289,  88.8118,  90.5088,  98.2829,\n",
      "         88.4686,  92.1415,  97.0283,  90.9142,  88.5981,  93.2660,  88.3070,\n",
      "         88.7428,  94.5851,  88.3280,  89.8763,  90.0077,  86.4405,  94.9193,\n",
      "         96.9912,  94.6336,  93.8175,  91.9225,  89.6763,  93.8024,  97.3102,\n",
      "         88.0318,  93.3051,  86.9246,  89.4857,  96.4626,  90.7316,  90.5267,\n",
      "         90.3371,  95.0095, 100.6196,  99.9191,  94.9369,  99.5934, 100.3442,\n",
      "         97.2174,  94.4796,  89.8802,  99.2872,  95.3858,  95.0289,  92.4168,\n",
      "         89.5162,  85.7678,  91.3291,  96.8562, 103.1101,  91.5500,  90.7623,\n",
      "         92.2981, 100.9671,  99.9549,  89.2386,  95.4874,  94.1440,  97.6203,\n",
      "        100.0036,  93.8435, 102.7540,  94.0648,  91.7056,  90.7341,  89.9290,\n",
      "         88.9276,  94.7977,  95.6397,  90.4365,  94.9870,  94.9730,  94.4804,\n",
      "         93.9925,  88.9106,  95.2023,  94.3518,  91.7088, 100.3290, 104.7396,\n",
      "         96.1485,  90.1793,  94.4971,  91.2682,  92.3933,  92.3625,  92.3381,\n",
      "         95.3194,  88.6234,  92.1102,  91.5806,  91.4453,  92.4826,  97.3611,\n",
      "         96.9013,  95.0407,  90.3374,  89.9460,  96.5803,  93.2900,  94.8461,\n",
      "         88.8493,  95.3465,  94.4584,  92.1671,  93.0932,  95.5812,  94.3726,\n",
      "         90.5150,  89.6013,  90.9454,  94.1111,  98.8227,  90.8675,  93.5775,\n",
      "         89.2887,  89.4803,  94.4655,  96.4229,  96.4927,  95.4089,  98.6210,\n",
      "         98.5141,  95.1294,  93.9585,  91.6555, 108.0772,  98.8779,  91.4217,\n",
      "         93.6068,  91.9959,  94.9811,  89.1965,  95.4877,  95.5195,  98.2634,\n",
      "         94.7196,  90.6825,  98.8333,  94.6768,  91.6795,  94.9580,  94.1993,\n",
      "         92.0851, 101.6263, 102.0614, 101.7571,  82.9206,  86.1761, 100.9493,\n",
      "         85.7910,  98.9177,  92.1668,  95.9538], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "see_channel_importances(mofa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Subnet Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet = sample_subnet_kernel(mofa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_units': 5,\n",
       " 'in_ch': 3,\n",
       " 'out_class': 100,\n",
       " 'width_list': [[256, 256, 256],\n",
       "  [256, 256, 256],\n",
       "  [256, 256, 256],\n",
       "  [256, 256, 256],\n",
       "  [256, 256, 256]],\n",
       " 'kernel_list': [[1, 3, 1], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
       " 'bias_list': [[True, True, True],\n",
       "  [True, True, True],\n",
       "  [True, True, True],\n",
       "  [True, True, True],\n",
       "  [True, True, True]],\n",
       " 'bn': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(subnet.param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "subnet = subnet.to(device)\n",
    "subnet.eval()\n",
    "with torch.no_grad():\n",
    "    for data in valset:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = subnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        break\n",
    "#     val_accuracy = correct / total\n",
    "#     if val_accuracy > best_val_accuracy:\n",
    "#         if epoch is not 0:\n",
    "#             os.remove(f'mofa_models/ofa_acc{100*best_val_accuracy:.0f}%.pth.tar')\n",
    "#         torch.save(mofa, f'mofa_models/ofa_acc{100*val_accuracy:.0f}%.pth.tar')\n",
    "#         best_val_accuracy = val_accuracy\n",
    "print(correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
